---
title: "Untitled"
author: "Josh Browning"
date: "July 14, 2016"
output: html_document
---

First, we load the data and the necessary libraries:

```{r}
suppressPackageStartupMessages({
library(data.table)
library(bit64)
library(venneuler)
library(ggplot2)
library(scales)
library(maps)
library(mapdata)
})
# events = fread("data/app_events.csv")
# labels = fread("data/app_labels.csv")
train = fread("data/gender_age_train.csv")
test = fread("data/gender_age_test.csv")
split_rate = nrow(test) / (nrow(train) + nrow(test))
```

Define a venn diagram plotting function:

```{r}
myVenn = function(A, B){
    sizeAnotB = length(unique(A[!A %in% B]))
    sizeBnotA = length(unique(B[!B %in% A]))
    AandB = A[A %in% B]
    if(length(AandB) > 0)
        sizeAandB = length(unique(A[A %in% B]))
    else
        sizeAandB = 0
    v = venneuler(c(A=sizeAnotB, B=sizeBnotA, "A&B"=sizeAandB))
    plot(v)
}
```

Let's first confirm that the device id's between test and train do not overlap at all:

```{r, echo=FALSE}
myVenn(train$device_id, test$device_id)
```

So, there's no overlap, just like we would have expected.

## Brand

What if we look at distributions by phone brand?

```{r}
phone_brand = fread("data/phone_brand_device_model.csv")
phone_brand[, train := device_id %in% train$device_id]
phone_brand[, test := device_id %in% test$device_id]
brand_cnts = phone_brand[, .N, by=phone_brand][order(N, decreasing=TRUE), ]
phone_brand[, phone_brand := factor(phone_brand, levels=brand_cnts$phone_brand)]
ggplot(phone_brand, aes(x=phone_brand, fill=train, color=train)) + geom_bar() +
    scale_x_discrete(breaks=brand_cnts$phone_brand, labels=rep("", nrow(brand_cnts)))
```

Most phones fall into one of a few different brands, but there are a total of 131 brands!  We can also look at the proportion of users within each brand that are in test/train (again, the below graph is sorted from highest brand by volume on the left to lowest brand by volume on the right):

```{r}
ggplot(phone_brand, aes(x=phone_brand)) +
    geom_bar(position="fill", aes(fill=train, color=train)) +
    scale_x_discrete(breaks=brand_cnts$phone_brand, labels=rep("", nrow(brand_cnts)))
```

Let's confirm all device id's fall into either train or test:

```{r}
phone_brand[, all(xor(train, test))]
```

What about multiple records for one device_id?

```{r}
duplicate_device_id = phone_brand[, list(device_cnt = length(unique(paste0(phone_brand, " - ", device_model)))),
                                         by=device_id][device_cnt > 1, device_id]
phone_brand[device_id %in% duplicate_device_id, ][order(device_id)]
```

## Events Data

Spatial density of observations in the training dataset:

```{r}
events = fread("data/events.csv")
events[, train := events$device_id %in% train$device_id]
events[, test := events$device_id %in% test$device_id]
china_map = fortify(map("china", fill=FALSE, plot=FALSE))
long_coordinates = c(70, 135)
lat_coordinates = c(15, 55)
ggplot() +
    geom_polygon(data=china_map, aes(x=long, y=lat, group=group, color=NULL, fill=NULL)) +
    stat_density2d(data=events[(train), ], aes(x=longitude, y=latitude, fill = ..level..), geom="polygon", alpha=0.5) +
    coord_cartesian(xlim=long_coordinates, ylim=lat_coordinates) +
    labs(fill="")
```

Spatial density of observations in the testing dataset:

```{r}
ggplot() +
    geom_polygon(data=china_map, aes(x=long, y=lat, group=group, color=NULL, fill=NULL)) +
    stat_density2d(data=events[(test), ], aes(x=longitude, y=latitude, fill = ..level..), geom="polygon", alpha=0.5) +
    coord_cartesian(xlim=long_coordinates, ylim=lat_coordinates) +
    labs(fill="")
```

The distribution of event counts seems split very evenly between test and train:

```{r}
event_cnts = events[, .N, by=c("device_id", "train")]
ggplot(event_cnts, aes(x=N, fill=train)) + geom_histogram() +
    scale_x_log10()
```

This consistency is even more clear when we plot the percentage within each group:

```{r}
ggplot(event_cnts, aes(x=N, fill=train)) + geom_histogram(position="fill") +
    scale_x_log10() + scale_y_continuous("percent", label=percent)
```

```{r}
events[, timestamp := as.POSIXct(timestamp)]
ggplot(events, aes(x=timestamp, fill=train)) + geom_histogram(binwidth=1)
ggplot(events, aes(x=timestamp, fill=train)) + geom_histogram(binwidth=1, position="fill")
```

```{r}
events[, time := strftime(timestamp, format="%H:%M:%S")]
events[, time_of_day := as.POSIXct(time, format="%H:%M:%S")]
ggplot(events, aes(x=time_of_day, fill=train)) + geom_histogram()
ggplot(events, aes(x=time_of_day, fill=train)) + geom_histogram(position="fill")
```

## Apps

```{r}
app_events = fread("data/app_events.csv")
labels = fread("data/app_labels.csv")
app_events = merge(app_events, events[, c("event_id", "train"), with=FALSE], by="event_id", all.x=TRUE)
```

Do any app events not have an assosciated event_id in events?

```{r}
app_events[is.na(train), ]
```

Can one event have multiple apps?

```{r}
apps_per_event = app_events[, list(count=.N), by=c("event_id", "train")]
apps_per_event[order(count), ]
```

Yes, as many as 320 apps in one event!  Ok, let's look at the distribution of these events:

```{r}
ggplot(apps_per_event, aes(x=count, fill=train, color=train)) + geom_histogram() 
```

```{r}
ggplot(apps_per_event, aes(x=count, fill=train, color=train)) + geom_histogram(position="fill") +
    scale_y_continuous("percent", label=percent)
```

Now, what if we restrict our attention to only apps that were active or installed?  It seems that is_installed will not be a useful feature, since it's always 1:

```{r}
app_events[, .N, is_installed]
```

The number of active apps per event is generally smaller than the number of non-active apps per event (rarely more than 50 active apps per event, while this is not too uncommon for non-active apps).  However, the number of events with non-active apps is much smaller overall.

```{r}
apps_per_event = app_events[, list(count=.N), by=c("event_id", "train", "is_active")]
ggplot(apps_per_event, aes(x=count, fill=train, color=train)) + geom_histogram() +
    facet_wrap( ~ is_active)
```

However, the distribution between test and train seems to be roughly what we'd expect if the split were done randomly:

```{r}
ggplot(apps_per_event, aes(x=count, fill=train, color=train)) + geom_histogram(position="fill") +
    scale_y_continuous("percent", label=percent) + facet_wrap( ~ is_active)
```

Categorizing these app events:

```{r}
labels[, .N, by=app_id][order(N), ]
labels[, .N, by=app_id][, mean(N > 1)]
```

So, one particular app can have multiple categories (as many as 26!).  This is very common, as 93% of these apps have more than one category.

```{r}
app_events = merge(app_events, labels, by="app_id", all.x=TRUE, allow.cartesian=TRUE)
app_events[is.na(label_id), ]
```

Now, let's see if there's any apparent bias among these app categories between train and test:

```{r}
label_cnts = app_events[, .N, by=label_id][order(N, decreasing=TRUE), ]
app_events[, labels := factor(labels, levels=label_cnts$label_id)]
ggplot(app_events, aes(x=label_id, fill=train, color=train)) + geom_bar() +
    scale_x_discrete(breaks=label_cnts$label_id, labels=rep("", nrow(label_cnts)))
```

```{r}
ggplot(app_events, aes(x=label_id, fill=train, color=train)) + geom_bar(position="fill") +
    scale_x_discrete(breaks=label_cnts$label_id, labels=rep("", nrow(label_cnts)))
```