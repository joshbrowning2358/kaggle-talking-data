---
title: "Exploratory Analysis"
author: "Josh Browning"
date: "July 14, 2016"
output: html_document
---

First, we load the data and the necessary libraries:

```{r}
suppressPackageStartupMessages({
library(data.table)
library(bit64)
library(venneuler)
library(ggplot2)
library(scales)
library(ggmap)
library(mapplots)
})
source("R/myVenn.R")
source("R/plot_proportions.R")
train = fread("data/gender_age_train.csv")
test = fread("data/gender_age_test.csv")
split_rate = nrow(test) / (nrow(train) + nrow(test))
```

Let's first confirm that the device id's between test and train do not overlap at all:

```{r, echo=FALSE}
myVenn(train$device_id, test$device_id)
```

So, there's no overlap, just like we would have expected.

## Brand

What if we look at distributions by phone brand?

```{r, echo=FALSE}
phone_brand = fread("data/phone_brand_device_model.csv")
phone_brand[, train := device_id %in% train$device_id]
phone_brand[, test := device_id %in% test$device_id]
myVenn(unique(phone_brand[(train), phone_brand]), unique(phone_brand[!(train), phone_brand]))
```

There is quite high overlap.  How many brands don't overlap?  How many users does this correspond to?

```{r}
brand_train_only = setdiff(unique(phone_brand[(train), phone_brand]),
                           unique(phone_brand[!(train), phone_brand]))
phone_brand[phone_brand %in% brand_train_only, .N, phone_brand]
brand_test_only = setdiff(unique(phone_brand[(test), phone_brand]),
                           unique(phone_brand[!(test), phone_brand]))
phone_brand[phone_brand %in% brand_test_only, .N, phone_brand]
```

```{r}
brand_cnts = phone_brand[, .N, by=phone_brand][order(N, decreasing=TRUE), ]
phone_brand[, phone_brand := factor(phone_brand, levels=brand_cnts$phone_brand)]
ggplot(phone_brand, aes(x=phone_brand, fill=train, color=train)) + geom_bar() +
    scale_x_discrete(breaks=brand_cnts$phone_brand, labels=rep("", nrow(brand_cnts)))
```

Most phones fall into one of a few different brands, but there are a total of 131 brands!  We can also look at the proportion of users within each brand that are in test/train.  In the below graph, each point represents a particular brand, with the x axis representing the (total) number of devices with that brand and the y axis representing the proportion of devices that are in the training set.  We'd expect, with 99\% confidence, that each point falls within the shaded region (a 99\% confidence interval):

```{r}
toPlot = phone_brand[, list(count=.N, proportion=mean(train)), by=phone_brand]
toPlot = toPlot[count > 10, ]
plot_proportions(toPlot, true_prop=1 - split_rate) + 
    scale_x_log10() + labs(title="Distributions of counts vs. proportions for phone brands")
```

And, just to be sure, let's plot the same graph for device_model:

```{r}
toPlot = phone_brand[, list(count=.N, proportion=mean(train)), by=device_model]
toPlot = toPlot[count > 10, ]
plot_proportions(toPlot, true_prop=1 - split_rate) + 
    scale_x_log10() + labs(title="Distributions of counts vs. proportions for device types")
```

Let\'s confirm all device id's fall into either train or test:

```{r}
phone_brand[, all(xor(train, test))]
```

What about multiple records for one device_id?

```{r}
duplicate_device_id = phone_brand[, list(device_cnt = length(unique(paste0(phone_brand, " - ", device_model)))),
                                         by=device_id][device_cnt > 1, device_id]
phone_brand[device_id %in% duplicate_device_id, ][order(device_id)]
```

## Events Data: Location

Spatial plot of the locations of events in the dataset

```{r}
events = fread("data/events.csv")
events[, train := events$device_id %in% train$device_id]
events[, test := events$device_id %in% test$device_id]
long_coordinates <- c(73.49941, 134.77281)
lat_coordinates <- c(18.15762, 53.55811)
ggplot() +
    borders("world", regions = "China", colour = "gray50", fill = "gray50") +
    geom_point(data=events, aes(x=longitude, y=latitude, color=ifelse(train, "Train", "Test")),
               size=0.05, alpha=0.5) +
    coord_cartesian(xlim=long_coordinates, ylim=lat_coordinates) +
    labs(fill="", color="")
```

Spatial density of observations in the training dataset:

```{r}
ggplot() +
    borders("world", regions = "China", colour = "gray50", fill = "gray50") +
    stat_density2d(data=events[(train), ], aes(x=longitude, y=latitude, fill = ..level..), geom="polygon", alpha=0.5) +
    coord_cartesian(xlim=long_coordinates, ylim=lat_coordinates) +
    labs(fill="")
```

Spatial density of observations in the testing dataset:

```{r}
ggplot() +
    borders("world", regions = "China", colour = "gray50", fill = "gray50") +
    stat_density2d(data=events[(test), ], aes(x=longitude, y=latitude, fill = ..level..), geom="polygon", alpha=0.5) +
    coord_cartesian(xlim=long_coordinates, ylim=lat_coordinates) +
    labs(fill="")
```

And histograms of the univariate latitude/longitude:

```{r}
ggplot(events, aes(x=latitude, color=train, fill=train)) +
    geom_histogram(binwidth=2)
```

```{r}
toPlot = events[, list(count=.N, proportion=mean(train)), by=round(latitude, 1)]
plot_proportions(toPlot[count > 10, ], true_prop=1-split_rate) + scale_x_log10()
```

```{r}
ggplot(events, aes(x=longitude, color=train, fill=train)) +
    geom_histogram(binwidth=2)
```

```{r}
toPlot = events[, list(count=.N, proportion=mean(train)), by=round(longitude, 1)]
plot_proportions(toPlot[count > 10, ], true_prop=1-split_rate) + scale_x_log10()
```

## Events Data: Counts and Time

The distribution of event counts seems split very evenly between test and train:

```{r}
event_cnts = events[, .N, by=c("device_id", "train")]
ggplot(event_cnts, aes(x=N, fill=train)) + geom_histogram() +
    scale_x_log10()
```

This consistency is even more clear when we plot the percentage within each group:

```{r}
toPlot = event_cnts[, list(count=.N, proportion=mean(train)), by=N]
plot_proportions(toPlot, true_prop=1-split_rate) + scale_x_log10()
```

```{r}
events[, timestamp := as.POSIXct(timestamp)]
ggplot(events, aes(x=timestamp, fill=train)) + geom_histogram(binwidth=1)
ggplot(events, aes(x=timestamp, fill=train)) + geom_histogram(binwidth=1, position="fill")
```

```{r}
events[, numericHour := round(as.numeric(timestamp)/3600)]
toPlot = events[, list(proportion=mean(train), count=.N), by=numericHour]
plot_proportions(toPlot, true_prop=1-split_rate)
```

```{r}
events[, weight_in_sum := 1/.N, by=device_id]
toPlot = events[, list(proportion=sum(weight_in_sum * train)/sum(weight_in_sum),
                       count=sum(weight_in_sum)),
                by=numericHour]
plot_proportions(toPlot, true_prop=1-split_rate)
```

```{r}
events[, time := strftime(timestamp, format="%H:%M:%S")]
events[, time_of_day := as.POSIXct(time, format="%H:%M:%S")]
ggplot(events, aes(x=time_of_day, fill=train)) + geom_histogram()
ggplot(events, aes(x=time_of_day, fill=train)) + geom_histogram(position="fill")
```

## Apps

```{r}
app_events = fread("data/app_events.csv")
labels = fread("data/app_labels.csv")
app_events = merge(app_events, events[, c("event_id", "train"), with=FALSE], by="event_id", all.x=TRUE)
```

Do any app events not have an assosciated event_id in events?

```{r}
app_events[is.na(train), ]
```

Can one event have multiple apps?

```{r}
apps_per_event = app_events[, list(count=.N), by=c("event_id", "train")]
apps_per_event[order(count), ]
```

Yes, as many as 320 apps in one event!  Ok, let's look at the distribution of these events:

```{r}
ggplot(apps_per_event, aes(x=count, fill=train, color=train)) + geom_histogram() 
```

```{r}
ggplot(apps_per_event, aes(x=count, fill=train, color=train)) + geom_histogram(position="fill") +
    scale_y_continuous("percent", label=percent)
```

Now, what if we restrict our attention to only apps that were active or installed?  It seems that is_installed will not be a useful feature, since it's always 1:

```{r}
app_events[, .N, is_installed]
```

The number of active apps per event is generally smaller than the number of non-active apps per event (rarely more than 50 active apps per event, while this is not too uncommon for non-active apps).  However, the number of events with non-active apps is much smaller overall.

```{r}
apps_per_event = app_events[, list(count=.N), by=c("event_id", "train", "is_active")]
ggplot(apps_per_event, aes(x=count, fill=train, color=train)) + geom_histogram() +
    facet_wrap( ~ is_active)
```

However, the distribution between test and train seems to be roughly what we'd expect if the split were done randomly:

```{r}
ggplot(apps_per_event, aes(x=count, fill=train, color=train)) + geom_histogram(position="fill") +
    scale_y_continuous("percent", label=percent) + facet_wrap( ~ is_active)
```

Categorizing these app events:

```{r}
labels[, .N, by=app_id][order(N), ]
labels[, .N, by=app_id][, mean(N > 1)]
```

So, one particular app can have multiple categories (as many as 26!).  This is very common, as 93% of these apps have more than one category.

```{r}
app_events = merge(app_events, labels, by="app_id", all.x=TRUE, allow.cartesian=TRUE)
app_events[is.na(label_id), ]
```

Now, let's see if there's any apparent bias among these app categories between train and test:

```{r}
label_cnts = app_events[, .N, by=label_id][order(N, decreasing=TRUE), ]
app_events[, labels := factor(labels, levels=label_cnts$label_id)]
ggplot(app_events, aes(x=label_id, fill=train, color=train)) + geom_bar() +
    scale_x_discrete(breaks=label_cnts$label_id, labels=rep("", nrow(label_cnts)))
```

```{r}
ggplot(app_events, aes(x=label_id, fill=train, color=train)) + geom_bar(position="fill") +
    scale_x_discrete(breaks=label_cnts$label_id, labels=rep("", nrow(label_cnts)))
```